# Docker Examples for GRIN-to-S3

This directory contains Docker configuration examples for running GRIN-to-S3 with different storage backends.

## Quick Start

### 1. Development with MinIO (Recommended for Testing)

```bash
# Start MinIO and application
docker-compose up -d

# Run a collection command
docker-compose exec grin-to-s3 python grin.py collect \
  --run-name test_run \
  --library-directory Harvard \
  --storage minio \
  --bucket-raw grin-raw \
  --bucket-meta grin-meta \
  --bucket-full grin-full \
  --limit 10

# Access MinIO console at http://localhost:9001 (minioadmin/minioadmin123)
```

### 2. Production with Cloudflare R2

```bash
# 1. Copy and configure credentials
cp examples/docker/r2-credentials-template.json examples/docker/r2-credentials.json
# Edit r2-credentials.json with your actual credentials

# 2. Set up OAuth2 credentials (run once)
docker-compose -f examples/docker/docker-compose.r2.yml run --rm grin-to-s3 auth setup

# 3. Run the application
docker-compose -f examples/docker/docker-compose.r2.yml up -d
```

### 3. Production with AWS S3

```bash
# 1. Copy and configure credentials
cp examples/docker/aws-credentials-template.json examples/docker/aws-credentials.json
# Edit aws-credentials.json with your actual credentials

# 2. Set up OAuth2 credentials (run once)
docker-compose -f examples/docker/docker-compose.s3.yml run --rm grin-to-s3 auth setup

# 3. Run the application
docker-compose -f examples/docker/docker-compose.s3.yml up -d
```

## Credential Management

### OAuth2 Credentials (Required for GRIN Access)

All configurations require OAuth2 credentials for accessing the GRIN API:

1. **client_secret.json** - OAuth2 client configuration from Google Cloud Console
2. **credentials.json** - User authentication tokens (generated by `auth setup`)

Create these files in the `examples/docker/` directory:

```bash
# Set up OAuth2 credentials
docker-compose -f <your-config>.yml run --rm grin-to-s3 auth setup
```

### Storage Credentials

#### Cloudflare R2
Create `examples/docker/r2-credentials.json`:
```json
{
  "endpoint_url": "https://your-account-id.r2.cloudflarestorage.com",
  "access_key": "your-r2-access-key-id",
  "secret_key": "your-r2-secret-access-key",
  "bucket_raw": "your-raw-bucket-name",
  "bucket_meta": "your-metadata-bucket-name",
  "bucket_full": "your-fulltext-bucket-name"
}
```

#### AWS S3
Create `examples/docker/aws-credentials.json`:
```json
{
  "access_key_id": "your-aws-access-key-id",
  "secret_access_key": "your-aws-secret-access-key",
  "region": "us-east-1",
  "bucket_raw": "your-raw-bucket-name",
  "bucket_meta": "your-metadata-bucket-name",
  "bucket_full": "your-fulltext-bucket-name"
}
```

#### MinIO (Development)
MinIO uses default credentials configured in docker-compose.dev.yml:
- Access Key: `minioadmin`
- Secret Key: `minioadmin123`
- Endpoint: `http://minio:9000`

### GPG Key (Optional)

If you need to decrypt GPG-encrypted files, mount your GPG key:

```bash
# Export your GPG key
gpg --export-secret-keys your-key-id > examples/docker/gpg-key.asc

# Uncomment the GPG volume mount in your docker-compose file
```

## Common Commands

### Collection
```bash
# Basic collection
docker-compose exec grin-to-s3 python grin.py collect \
  --run-name my_collection \
  --library-directory Harvard \
  --storage r2 \
  --limit 1000

# With custom buckets
docker-compose exec grin-to-s3 python grin.py collect \
  --run-name my_collection \
  --library-directory Harvard \
  --storage r2 \
  --bucket-raw my-raw \
  --bucket-meta my-meta \
  --bucket-full my-full
```

### Processing
```bash
# Request processing
docker-compose exec grin-to-s3 python grin.py process request \
  --run-name my_collection \
  --limit 500

# Monitor processing
docker-compose exec grin-to-s3 python grin.py process monitor \
  --run-name my_collection
```

### Sync
```bash
# Sync converted books
docker-compose exec grin-to-s3 python grin.py sync pipeline \
  --run-name my_collection

# Check sync status
docker-compose exec grin-to-s3 python grin.py sync status \
  --run-name my_collection
```

### Export
```bash
# Export to CSV
docker-compose exec grin-to-s3 python grin.py export \
  --run-name my_collection \
  --output /app/output/books.csv

# Copy CSV to host
docker cp grin-to-s3:/app/output/books.csv ./books.csv
```

## Data Persistence

All Docker configurations use volumes for persistent data:

- **data/** - SQLite databases and progress files
- **output/** - Run outputs and results
- **config/** - Authentication and configuration files
- **logs/** - Application logs
- **staging/** - Temporary processing files

Data is stored in `./docker-data/` on the host system.

## Troubleshooting

### Permission Issues
```bash
# Fix permissions for data directories
sudo chown -R 1000:1000 ./docker-data/
```

### Credential Issues
```bash
# Check if credentials are mounted correctly
docker-compose exec grin-to-s3 ls -la /app/config/

# Test storage connection
docker-compose exec grin-to-s3 python grin.py storage ls --run-name test
```

### Log Access
```bash
# View application logs
docker-compose logs grin-to-s3

# View application log files
docker-compose exec grin-to-s3 tail -f /app/logs/grin_pipeline_*.log
```

### MinIO Access
When using development MinIO:
- Console: http://localhost:9001
- API: http://localhost:9000
- Username: minioadmin
- Password: minioadmin123

## Security Notes

1. Never commit credential files to version control
2. Use read-only mounts for credential files
3. Consider using Docker secrets for production deployments
4. Rotate credentials regularly
5. Use least-privilege access for storage bucket permissions